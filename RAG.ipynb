{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPYoitZxN2aXhzBOFvNFL5y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Simple RAG implementation\n"],"metadata":{"id":"VCCr4V0kiyPU"}},{"cell_type":"markdown","source":["##Mount with drive"],"metadata":{"id":"sEfq7S1ii81B"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"ZPAPk6cdAFy3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Implementation\n","###Setup\n","Install required libraries"],"metadata":{"id":"tU08DoSJjIx7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-jK82Mry_cH9"},"outputs":[],"source":["!pip install langchain openai faiss-cpu tiktoken chromadb"]},{"cell_type":"code","source":["!pip install python-dotenv\n"],"metadata":{"id":"twuuZfnEYPQ3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load env variables"],"metadata":{"id":"M6Vv7QyTjQfx"}},{"cell_type":"code","source":["import os\n","from dotenv import load_dotenv\n","\n","# Load the .env file\n","load_dotenv()\n","\n","# Read the key\n","api_key = os.getenv(\"OPEN_AI\")\n","\n","# Print to check\n","print(f\"API Key: {api_key}\")\n"],"metadata":{"collapsed":true,"id":"iWDSOR_5YWoa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get open ai key"],"metadata":{"id":"8klSsjUnjUXz"}},{"cell_type":"code","source":["# OpenAI API Key\n","\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = api_key\n","\n"],"metadata":{"id":"dml-ZeXjB8QD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Install more required libs"],"metadata":{"id":"VZZbI6ydjXO2"}},{"cell_type":"code","source":["!pip install --upgrade langchain langchain-community langchain-openai\n"],"metadata":{"id":"G4agF35_DvuX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###RAG"],"metadata":{"id":"7xE5EItYjj9K"}},{"cell_type":"code","source":["from langchain.document_loaders import TextLoader\n","\n","# Create a sample text file\n","data_text = \"\"\"Machine learning is a subset of artificial intelligence that enables computers to learn from data without being explicitly programmed.\n","Retrieval-Augmented Generation (RAG) enhances LLMs by retrieving relevant documents from a knowledge base before generating an answer.\n","FAISS is a library developed by Facebook AI for efficient similarity search and clustering of dense vectors.\n","\"\"\"\n","\n","with open(\"/content/drive/MyDrive/LLM-Projects/RAG/data.txt\", \"w\") as f:\n","    f.write(data_text)\n","\n","# Load the text file\n","loader = TextLoader(\"/content/drive/MyDrive/LLM-Projects/RAG/data.txt\")\n","documents = loader.load()\n","\n","\n"],"metadata":{"id":"Tr4iNup_DQJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","\n","# Split the document into smaller chunks\n","splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n","texts = splitter.split_documents(documents)\n","\n","# Create FAISS vector store from embeddings\n","vector_store = FAISS.from_documents(texts, OpenAIEmbeddings())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TN5T20FC2rd","executionInfo":{"status":"ok","timestamp":1739668487725,"user_tz":300,"elapsed":1892,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"3d75563e-b8f8-45b2-d4c2-cc5695e14ea7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test\n"]}]},{"cell_type":"code","source":["retriever = vector_store.as_retriever()"],"metadata":{"id":"bxe7kNzaEFS5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.chains import RetrievalQA\n","from langchain.chat_models import ChatOpenAI\n","\n","# Create a RAG-powered Q&A system\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm=ChatOpenAI(model_name=\"gpt-4\"),\n","    retriever=retriever\n",")\n","\n","# Ask a question\n","query = \"What is RAG in AI?\"\n","response = qa_chain.run(query)\n","\n","print(f\"Q: {query}\")\n","print(f\"A: {response}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLOtQxG1EJa6","executionInfo":{"status":"ok","timestamp":1739665742094,"user_tz":300,"elapsed":3696,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"98b78b41-7a5e-4812-8e97-d63fc6d6e016"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-3149bd18d9b5>:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n","  llm=ChatOpenAI(model_name=\"gpt-4\"),\n","<ipython-input-12-3149bd18d9b5>:12: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n","  response = qa_chain.run(query)\n"]},{"output_type":"stream","name":"stdout","text":["Q: What is RAG in AI?\n","A: RAG, or Retrieval-Augmented Generation, in AI refers to a method that enhances Language Models by retrieving relevant documents from a knowledge base before generating an answer. This helps improve the accuracy and relevance of the model's responses.\n"]}]},{"cell_type":"code","source":["while True:\n","    query = input(\"\\nAsk a question (or type 'exit' to quit): \")\n","    if query.lower() == \"exit\":\n","        break\n","    response = qa_chain.run(query)\n","    print(f\"\\nðŸ¤– Answer: {response}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7P3waQABER0n","executionInfo":{"status":"ok","timestamp":1739665779304,"user_tz":300,"elapsed":33466,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"ae4389c7-a903-4e90-acc0-eb264b062df5"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Ask a question (or type 'exit' to quit): what should I do on a rainy day?\n","\n","ðŸ¤– Answer: I'm sorry, but the provided context doesn't contain any information on what to do on a rainy day.\n","\n","Ask a question (or type 'exit' to quit): exit\n"]}]},{"cell_type":"markdown","source":["## Git commands"],"metadata":{"id":"XReEJp_eihIG"}},{"cell_type":"code","source":["!git add .\n","!git commit -m \"Organize codes and initial commit\"\n"," # Replace 'main' with your branch name if different\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-n3CHDCL3Bj","executionInfo":{"status":"ok","timestamp":1739673165653,"user_tz":300,"elapsed":1043,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"a86df64d-3c1c-44a3-8795-f899cb6ba27d"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch and 'origin/main' have diverged,\n","and have 5 and 1 different commits each, respectively.\n","  (use \"git pull\" to merge the remote branch into yours)\n","\n","nothing to commit, working tree clean\n"]}]},{"cell_type":"code","source":["!git pull"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nuKz_K8akDMe","executionInfo":{"status":"ok","timestamp":1739673189148,"user_tz":300,"elapsed":1689,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"f0c0f888-8cba-444c-db3f-8bdb9fa960df"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Repository not found.\n","fatal: repository 'https://github.com/sabid-habib/llm-implementations.git/' not found\n"]}]},{"cell_type":"code","source":["!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xDswel7sNYGA","executionInfo":{"status":"ok","timestamp":1739672629140,"user_tz":300,"elapsed":1345,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"96d36103-ce4d-4dcf-d8da-09e5c91d7ee0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["To https://github.com/sabid-habib/llm-implementations.git\n"," \u001b[31m! [rejected]       \u001b[m main -> main (non-fast-forward)\n","\u001b[31merror: failed to push some refs to 'https://github.com/sabid-habib/llm-implementations.git'\n","\u001b[m\u001b[33mhint: Updates were rejected because the tip of your current branch is behind\u001b[m\n","\u001b[33mhint: its remote counterpart. Integrate the remote changes (e.g.\u001b[m\n","\u001b[33mhint: 'git pull ...') before pushing again.\u001b[m\n","\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n"]}]},{"cell_type":"code","source":["!git status\n"],"metadata":{"id":"HuUPCwZlNoI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/LLM-Projects/RAG-new/llm-things"],"metadata":{"id":"EJ94TsJzmtYc","executionInfo":{"status":"ok","timestamp":1739673246818,"user_tz":300,"elapsed":1032,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"d29e151d-20be-42bf-9cde-bb02e06bb100","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/LLM-Projects/RAG-new/llm-things\n"]}]}]}