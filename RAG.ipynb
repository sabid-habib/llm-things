{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNMlRBGTauUd4TUH4aT0E8K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Simple RAG implementation\n"],"metadata":{"id":"VCCr4V0kiyPU"}},{"cell_type":"markdown","source":["##Mount with drive"],"metadata":{"id":"sEfq7S1ii81B"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"ZPAPk6cdAFy3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739747717760,"user_tz":300,"elapsed":18583,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"fa7d9f02-9c2d-4627-9bed-990840e3224a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/LLM-Projects/RAG-new/llm-things"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBq4udK2DMy5","executionInfo":{"status":"ok","timestamp":1739747817919,"user_tz":300,"elapsed":220,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"95771fcf-03ed-4207-cec9-785c9fad6190"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/LLM-Projects/RAG-new/llm-things\n"]}]},{"cell_type":"markdown","source":["##Implementation\n","###Setup\n","Install required libraries"],"metadata":{"id":"tU08DoSJjIx7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-jK82Mry_cH9"},"outputs":[],"source":["!pip install langchain openai faiss-cpu tiktoken chromadb"]},{"cell_type":"code","source":["!pip install python-dotenv\n"],"metadata":{"id":"twuuZfnEYPQ3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load env variables"],"metadata":{"id":"M6Vv7QyTjQfx"}},{"cell_type":"code","source":["import os\n","from dotenv import load_dotenv\n","\n","# Load the .env file\n","load_dotenv()\n","\n","# Read the key\n","api_key = os.getenv(\"OPEN_AI\")\n","\n","# Print to check\n","print(f\"API Key: {api_key}\")\n"],"metadata":{"collapsed":true,"id":"iWDSOR_5YWoa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get open ai key"],"metadata":{"id":"8klSsjUnjUXz"}},{"cell_type":"code","source":["# OpenAI API Key\n","\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = api_key\n","\n"],"metadata":{"id":"dml-ZeXjB8QD","executionInfo":{"status":"ok","timestamp":1739747828329,"user_tz":300,"elapsed":2,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Install more required libs"],"metadata":{"id":"VZZbI6ydjXO2"}},{"cell_type":"code","source":["!pip install --upgrade langchain langchain-community langchain-openai\n"],"metadata":{"id":"G4agF35_DvuX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###RAG"],"metadata":{"id":"7xE5EItYjj9K"}},{"cell_type":"code","source":["from langchain.document_loaders import TextLoader\n","\n","# Create a sample text file\n","data_text = \"\"\"Machine learning is a subset of artificial intelligence that enables computers to learn from data without being explicitly programmed.\n","Retrieval-Augmented Generation (RAG) enhances LLMs by retrieving relevant documents from a knowledge base before generating an answer.\n","FAISS is a library developed by Facebook AI for efficient similarity search and clustering of dense vectors.\n","\"\"\"\n","\n","with open(\"/content/drive/MyDrive/LLM-Projects/RAG/data.txt\", \"w\") as f:\n","    f.write(data_text)\n","\n","# Load the text file\n","loader = TextLoader(\"/content/drive/MyDrive/LLM-Projects/RAG/data.txt\")\n","documents = loader.load()\n","\n","\n"],"metadata":{"id":"Tr4iNup_DQJ8","executionInfo":{"status":"ok","timestamp":1739747874858,"user_tz":300,"elapsed":714,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","\n","# Split the document into smaller chunks\n","splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n","texts = splitter.split_documents(documents)\n","\n","# Create FAISS vector store from embeddings\n","vector_store = FAISS.from_documents(texts, OpenAIEmbeddings())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TN5T20FC2rd","executionInfo":{"status":"ok","timestamp":1739747880503,"user_tz":300,"elapsed":3195,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"d821a865-a6a7-4200-b181-a700ffd69f59"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-954af7759a9a>:10: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n","  vector_store = FAISS.from_documents(texts, OpenAIEmbeddings())\n"]}]},{"cell_type":"code","source":["retriever = vector_store.as_retriever()"],"metadata":{"id":"bxe7kNzaEFS5","executionInfo":{"status":"ok","timestamp":1739747882106,"user_tz":300,"elapsed":135,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from langchain.chains import RetrievalQA\n","from langchain.chat_models import ChatOpenAI\n","\n","# Create a RAG-powered Q&A system\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm=ChatOpenAI(model_name=\"gpt-4\"),\n","    retriever=retriever\n",")\n","\n","# Ask a question\n","query = \"What is RAG in AI?\"\n","response = qa_chain.run(query)\n","\n","print(f\"Q: {query}\")\n","print(f\"A: {response}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLOtQxG1EJa6","executionInfo":{"status":"ok","timestamp":1739665742094,"user_tz":300,"elapsed":3696,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"98b78b41-7a5e-4812-8e97-d63fc6d6e016"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-3149bd18d9b5>:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n","  llm=ChatOpenAI(model_name=\"gpt-4\"),\n","<ipython-input-12-3149bd18d9b5>:12: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n","  response = qa_chain.run(query)\n"]},{"output_type":"stream","name":"stdout","text":["Q: What is RAG in AI?\n","A: RAG, or Retrieval-Augmented Generation, in AI refers to a method that enhances Language Models by retrieving relevant documents from a knowledge base before generating an answer. This helps improve the accuracy and relevance of the model's responses.\n"]}]},{"cell_type":"code","source":["while True:\n","    query = input(\"\\nAsk a question (or type 'exit' to quit): \")\n","    if query.lower() == \"exit\":\n","        break\n","    response = qa_chain.run(query)\n","    print(f\"\\nðŸ¤– Answer: {response}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7P3waQABER0n","executionInfo":{"status":"ok","timestamp":1739747892387,"user_tz":300,"elapsed":7177,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"2ff2def7-5973-41f0-8ea4-82a621fee618"},"execution_count":11,"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Ask a question (or type 'exit' to quit): exit\n"]}]},{"cell_type":"code","source":["from fastapi import FastAPI\n","from pydantic import BaseModel\n","\n","app = FastAPI()\n","\n","class QueryRequest(BaseModel):\n","    query: str\n","\n","@app.post(\"/ask\")\n","async def ask_question(request: QueryRequest):\n","    response = qa_chain.run(request.query)\n","    return {\"answer\": response}\n"],"metadata":{"id":"HeOpkK1DDi06","executionInfo":{"status":"ok","timestamp":1739747900978,"user_tz":300,"elapsed":720,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["!pip install uvicorn fastapi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7gCcjPrEEWO","executionInfo":{"status":"ok","timestamp":1739748041988,"user_tz":300,"elapsed":3014,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"5f7673f1-b055-4184-d807-fc9fcee08fed"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.8)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n","Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.45.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.10.6)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n","Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.46.0,>=0.40.0->fastapi) (3.7.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.3.1)\n"]}]},{"cell_type":"code","source":["!uvicorn rag_api:app --host 0.0.0.0 --port 8000 --reload\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aESzpE23DmW0","executionInfo":{"status":"ok","timestamp":1739748303978,"user_tz":300,"elapsed":47199,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"a5402915-b861-485a-9519-80a0fae0a430"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/content/drive/MyDrive/LLM-Projects/RAG-new/llm-things']\n","\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n","\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m3118\u001b[0m] using \u001b[36m\u001b[1mWatchFiles\u001b[0m\n","\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m3124\u001b[0m]\n","\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n","\u001b[32mINFO\u001b[0m:     Application startup complete.\n","\u001b[32mINFO\u001b[0m:     Shutting down\n","\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n","\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n","\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m3124\u001b[0m]\n","\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m3118\u001b[0m]\n"]}]},{"cell_type":"markdown","source":["## Git commands"],"metadata":{"id":"XReEJp_eihIG"}},{"cell_type":"markdown","source":["Go to git repo"],"metadata":{"id":"vXuC9lEwm6K9"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/LLM-Projects/RAG-new/llm-things"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EJ94TsJzmtYc","executionInfo":{"status":"ok","timestamp":1739673246818,"user_tz":300,"elapsed":1032,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"d29e151d-20be-42bf-9cde-bb02e06bb100"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/LLM-Projects/RAG-new/llm-things\n"]}]},{"cell_type":"code","source":["!git add .\n","!git commit -m \"Uvicorn integration\"\n"," # Replace 'main' with your branch name if different\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-n3CHDCL3Bj","executionInfo":{"status":"ok","timestamp":1739748322607,"user_tz":300,"elapsed":3040,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"c258073c-15d1-45a9-b32c-3f07d737e5a1"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Author identity unknown\n","\n","*** Please tell me who you are.\n","\n","Run\n","\n","  git config --global user.email \"you@example.com\"\n","  git config --global user.name \"Your Name\"\n","\n","to set your account's default identity.\n","Omit --global to set the identity only in this repository.\n","\n","fatal: unable to auto-detect email address (got 'root@52beb05685d2.(none)')\n"]}]},{"cell_type":"code","source":["!git pull"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nuKz_K8akDMe","executionInfo":{"status":"ok","timestamp":1739673189148,"user_tz":300,"elapsed":1689,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"f0c0f888-8cba-444c-db3f-8bdb9fa960df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Repository not found.\n","fatal: repository 'https://github.com/sabid-habib/llm-implementations.git/' not found\n"]}]},{"cell_type":"code","source":["!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xDswel7sNYGA","executionInfo":{"status":"ok","timestamp":1739673272085,"user_tz":300,"elapsed":1692,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"b425f894-48fb-4c1d-c1c9-db2903f97921"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 4, done.\n","Counting objects:  25% (1/4)\rCounting objects:  50% (2/4)\rCounting objects:  75% (3/4)\rCounting objects: 100% (4/4)\rCounting objects: 100% (4/4), done.\n","Delta compression using up to 2 threads\n","Compressing objects:  33% (1/3)\rCompressing objects:  66% (2/3)\rCompressing objects: 100% (3/3)\rCompressing objects: 100% (3/3), done.\n","Writing objects:  25% (1/4)\rWriting objects:  50% (2/4)\rWriting objects:  75% (3/4)\rWriting objects: 100% (4/4)\rWriting objects: 100% (4/4), 3.44 KiB | 320.00 KiB/s, done.\n","Total 4 (delta 0), reused 0 (delta 0), pack-reused 0\n","To https://github.com/sabid-habib/llm-things.git\n"," * [new branch]      main -> main\n"]}]},{"cell_type":"code","source":["!git status\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HuUPCwZlNoI8","executionInfo":{"status":"ok","timestamp":1739673256562,"user_tz":300,"elapsed":5248,"user":{"displayName":"Sabid Bin Habib","userId":"04952409304336351800"}},"outputId":"6d217cb0-6084-450c-bd87-8db834a70e93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","\n","No commits yet\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31m.gitignore\u001b[m\n","\t\u001b[31mRAG.ipynb\u001b[m\n","\n","nothing added to commit but untracked files present (use \"git add\" to track)\n"]}]}]}